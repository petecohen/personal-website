---
title: "The Tipping Point"
date: 2026-01-02
summary: "The question is no longer 'is this real?'. It's 'is this plausible within the fiction?'"
externalUrl: "https://www.vibrance.au/post/the-tipping-point"
---

*Originally published at [Vibrance](https://www.vibrance.au/post/the-tipping-point)*

It was a photo of Einstein playing a Peavey Razer electric guitar that did it for me. Not the fact that it was fake - that was already assumed by everyone in the comments. The conversation was about whether Einstein would have played a Peavey. It didn't match his vibe, apparently.

That's when I knew we'd crossed over. The question is no longer "is this real?". It's "is this plausible within the fiction?"

![Einstein playing guitar](/einstein-photo-reddit.jpeg)
*Source: Reddit*

When I first saw that image on my social media feed a couple of weeks ago, I naturally assumed it had been AI generated. It was only when I searched for the source that I discovered it is over 15 years old - an example of what was possible in the early days of Photoshop. Waves of synthetic information have been lapping at the shore for a while. But it's different now. Few of us ever could master Photoshop, with its hundreds of little buttons and loupes and layers and whatnot. And even if you could, it still took hours of work to create anything decent. Now anyone can instruct an LLM what to do, and the result will be instant, free and near perfect. Whether it's a photo, a report or an essay, reaching for an AI tool is often easier than doing the labour of creating from scratch.

It feels like in a matter of months, our world has flipped. Where once the proof of work was long slide decks with carefully crafted insights and perfect formatting (which we reasonably assumed had been done by a human) we are now in a world where long and perfect is instant, easy and potentially lazy. We have to assume that anything we see or hear has been created, at least in part, by AI.

What does this mean for a culture where our first instinct is to question what is in front of our eyes?

At the broadest level, I'm not sure we've reckoned with it yet - what it means to live in a world where "true" and "plausible" have quietly decoupled. But I can see the shift playing out in innovation work, where I spend most of my time, and it's forcing a recalibration of what we actually value.

In a world where generation is nearly free, selection becomes the act of authorship. What you choose to hand over - why this, out of infinite possibilities - is now the signal of care, taste and intention.

Ironically, the Peavey guitar being recognisable is what sparked the whole conversation around the Einstein photo. A generic guitar wouldn't have provoked anything. Specificity provoked engagement. That feels like a clue.

So how do you hold onto specificity when the tools make generic so easy? I use LLMs constantly (I hope and assume you do too) but the way I use them is an attempt to protect something. Working with an LLM as a thought partner that pushes back on where my ideas need refinement is genuinely useful. When I work this way, whatever I'm building goes through dozens of iterations. The machine influences my thinking and I influence its output. Something emerges that neither of us would have arrived at alone.

But here's the friction: I don't always trust that others are doing the same.

I'm not talking about people copying and pasting wholesale LLM output as their own work. I'll give the benefit of the doubt that most people aren't doing that for anything that matters. But as we have all experienced by now, unless an LLM has been primed with carefully curated context, it returns fairly bland material. In innovation work, that creates drag. We're no longer building on novel ideas or dealing with the true essence of someone's hard-won insights. Instead, we're wading through grey goo - plausible sentences that lack the sharpness of a human who has actually been inside the problem. The editorial labour of finding signal amongst noise gets quietly transferred without consent, and I've come to dread it.

So what's left? Maybe the currency now is less in the answers - which have become cheap and easy to generate - and more in the questions we choose to ask. The willingness to take a position. The readiness to be shaped by each other in real time, through dialogue, even when we know the machines are playing their part in the background.

We've crossed a threshold. The old question - "is this real?" - hasn't disappeared, but it's no longer the first one we ask. We've learned to navigate synthetic content without establishing ground truth first. We just skip that step. I'm not sure we've fully understood what that costs us, or what it makes possible. But I suspect the people and organisations that thrive in this new landscape will be the ones who can still surprise us - who offer specificity, conviction, and the visible residue of having actually done the work.

The Peavey was a good choice after all.
